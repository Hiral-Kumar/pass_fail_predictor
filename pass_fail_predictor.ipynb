{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a_qpL5W2HGU"
      },
      "source": [
        "Pass Fail Predictor by Hiral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "y7hFMId-156e",
        "outputId": "0d8958d8-a07c-4b7a-df9c-6097f783af21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using dataset file: C:\\Users\\hiral\\Downloads\\student_pass_fail_dataset_10000.csv\n",
            "Dataset loaded successfully\n",
            "Dataset validation passed âœ”\n",
            "PHASE 1 COMPLETED SUCCESSFULLY\n"
          ]
        }
      ],
      "source": [
        "# ==============================\n",
        "# PHASE 1: DATASET LOAD & VALIDATION\n",
        "# ==============================\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# ------------------------------\n",
        "# Project Configuration\n",
        "# ------------------------------\n",
        "\n",
        "subjects = [\n",
        "    \"maths\",\n",
        "    \"science\",\n",
        "    \"english\",\n",
        "    \"hindi\",\n",
        "    \"social_science\",\n",
        "    \"computer_science\"\n",
        "]\n",
        "\n",
        "MARK_LIMITS = {\n",
        "    \"midsem\": 25,\n",
        "    \"quiz\": 10,\n",
        "    \"internal\": 15,\n",
        "    \"endsem\": 50,\n",
        "    \"total\": 100\n",
        "}\n",
        "\n",
        "PASSING_PERCENTAGE = 45\n",
        "\n",
        "# ------------------------------\n",
        "# Step 1: Load dataset from local system\n",
        "# ------------------------------\n",
        "\n",
        "dataset_path = r\"C:\\Users\\hiral\\Downloads\\student_pass_fail_dataset_10000.csv\"\n",
        "print(f\"Using dataset file: {dataset_path}\")\n",
        "\n",
        "# ------------------------------\n",
        "# Step 2: Load dataset\n",
        "# ------------------------------\n",
        "\n",
        "def load_dataset(file_path):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        print(\"Dataset loaded successfully\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Error loading dataset: {e}\")\n",
        "\n",
        "# ------------------------------\n",
        "# Step 3: Validate dataset\n",
        "# ------------------------------\n",
        "\n",
        "def validate_dataset(df):\n",
        "    required_columns = []\n",
        "\n",
        "    for subject in subjects:\n",
        "        required_columns.extend([\n",
        "            f\"{subject}_midsem\",\n",
        "            f\"{subject}_quiz\",\n",
        "            f\"{subject}_internal\",\n",
        "            f\"{subject}_endsem\",\n",
        "            f\"{subject}_total\"\n",
        "        ])\n",
        "\n",
        "    required_columns.append(\"attendance_score\")\n",
        "\n",
        "    missing_cols = set(required_columns) - set(df.columns)\n",
        "    if missing_cols:\n",
        "        raise ValueError(f\"Missing columns in dataset: {missing_cols}\")\n",
        "\n",
        "    for subject in subjects:\n",
        "        if not df[f\"{subject}_midsem\"].between(0, MARK_LIMITS[\"midsem\"]).all():\n",
        "            raise ValueError(f\"Invalid midsem marks in {subject}\")\n",
        "\n",
        "        if not df[f\"{subject}_quiz\"].between(0, MARK_LIMITS[\"quiz\"]).all():\n",
        "            raise ValueError(f\"Invalid quiz marks in {subject}\")\n",
        "\n",
        "        if not df[f\"{subject}_internal\"].between(0, MARK_LIMITS[\"internal\"]).all():\n",
        "            raise ValueError(f\"Invalid internal marks in {subject}\")\n",
        "\n",
        "        if not df[f\"{subject}_endsem\"].between(0, MARK_LIMITS[\"endsem\"]).all():\n",
        "            raise ValueError(f\"Invalid endsem marks in {subject}\")\n",
        "\n",
        "        if not df[f\"{subject}_total\"].between(0, MARK_LIMITS[\"total\"]).all():\n",
        "            raise ValueError(f\"Invalid total marks in {subject}\")\n",
        "\n",
        "    if not df[\"attendance_score\"].between(0.0, 10.0).all():\n",
        "        raise ValueError(\"Attendance score out of range (0â€“10)\")\n",
        "\n",
        "    if df.isnull().any().any():\n",
        "        raise ValueError(\"Dataset contains missing values\")\n",
        "\n",
        "    print(\"Dataset validation passed âœ”\")\n",
        "    return True\n",
        "\n",
        "# ------------------------------\n",
        "# Execute Phase 1\n",
        "# ------------------------------\n",
        "\n",
        "df = load_dataset(dataset_path)\n",
        "validate_dataset(df)\n",
        "\n",
        "print(\"PHASE 1 COMPLETED SUCCESSFULLY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "MKO9pxCqAxwS",
        "outputId": "41820a03-4d3b-4f70-ba99-dae76a7c4fe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PHASE 2 COMPLETED SUCCESSFULLY\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall_marks_avg</th>\n",
              "      <th>attendance_score</th>\n",
              "      <th>final_weighted_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60.500000</td>\n",
              "      <td>0.13</td>\n",
              "      <td>51.620000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>57.333333</td>\n",
              "      <td>9.54</td>\n",
              "      <td>63.043333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>51.166667</td>\n",
              "      <td>3.40</td>\n",
              "      <td>48.591667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>49.666667</td>\n",
              "      <td>9.32</td>\n",
              "      <td>56.196667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>58.000000</td>\n",
              "      <td>3.21</td>\n",
              "      <td>54.115000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   overall_marks_avg  attendance_score  final_weighted_score\n",
              "0          60.500000              0.13             51.620000\n",
              "1          57.333333              9.54             63.043333\n",
              "2          51.166667              3.40             48.591667\n",
              "3          49.666667              9.32             56.196667\n",
              "4          58.000000              3.21             54.115000"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ==============================\n",
        "# PHASE 2: SCORE CALCULATION & WEIGHTAGE\n",
        "# ==============================\n",
        "\n",
        "def calculate_subject_totals(df):\n",
        "    \"\"\"\n",
        "    Recalculate subject totals to ensure correctness\n",
        "    \"\"\"\n",
        "    for subject in subjects:\n",
        "        df[f\"{subject}_total\"] = (\n",
        "            df[f\"{subject}_midsem\"]\n",
        "            + df[f\"{subject}_quiz\"]\n",
        "            + df[f\"{subject}_internal\"]\n",
        "            + df[f\"{subject}_endsem\"]\n",
        "        )\n",
        "    return df\n",
        "\n",
        "\n",
        "def calculate_overall_average(df):\n",
        "    \"\"\"\n",
        "    Calculate average marks across all subjects (out of 100)\n",
        "    \"\"\"\n",
        "    total_columns = [f\"{subject}_total\" for subject in subjects]\n",
        "    df[\"overall_marks_avg\"] = df[total_columns].mean(axis=1)\n",
        "    return df\n",
        "\n",
        "\n",
        "def calculate_final_weighted_score(df):\n",
        "    \"\"\"\n",
        "    Apply 85% marks + 15% attendance weightage\n",
        "    \"\"\"\n",
        "    df[\"attendance_scaled\"] = df[\"attendance_score\"] * 10\n",
        "    df[\"final_weighted_score\"] = (\n",
        "        0.85 * df[\"overall_marks_avg\"]\n",
        "        + 0.15 * df[\"attendance_scaled\"]\n",
        "    )\n",
        "    return df\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Execute Phase 2\n",
        "# ------------------------------\n",
        "\n",
        "df = calculate_subject_totals(df)\n",
        "df = calculate_overall_average(df)\n",
        "df = calculate_final_weighted_score(df)\n",
        "\n",
        "print(\"PHASE 2 COMPLETED SUCCESSFULLY\")\n",
        "\n",
        "# Preview computed scores\n",
        "df[[\n",
        "    \"overall_marks_avg\",\n",
        "    \"attendance_score\",\n",
        "    \"final_weighted_score\"\n",
        "]].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "rvZdhZlGB-1q",
        "outputId": "3ab2809e-fad4-43ec-bfa6-059a93819fbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PHASE 3 COMPLETED SUCCESSFULLY\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>final_weighted_score</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>51.620000</td>\n",
              "      <td>PASS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>63.043333</td>\n",
              "      <td>FAIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>48.591667</td>\n",
              "      <td>FAIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56.196667</td>\n",
              "      <td>FAIL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>54.115000</td>\n",
              "      <td>FAIL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   final_weighted_score result\n",
              "0             51.620000   PASS\n",
              "1             63.043333   FAIL\n",
              "2             48.591667   FAIL\n",
              "3             56.196667   FAIL\n",
              "4             54.115000   FAIL"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ==============================\n",
        "# PHASE 3: PASS / FAIL CLASSIFICATION\n",
        "# ==============================\n",
        "\n",
        "# Safety check\n",
        "if 'df' not in globals():\n",
        "    raise NameError(\"Dataset not available. Run Phase 1 and Phase 2 first.\")\n",
        "\n",
        "PASSING_PERCENTAGE = 45\n",
        "\n",
        "def classify_pass_fail(df):\n",
        "    # Subject-wise pass check\n",
        "    for subject in subjects:\n",
        "        df[f\"{subject}_pass\"] = df[f\"{subject}_total\"] >= PASSING_PERCENTAGE\n",
        "\n",
        "    # Overall weighted score pass check\n",
        "    df[\"overall_pass\"] = df[\"final_weighted_score\"] >= PASSING_PERCENTAGE\n",
        "\n",
        "    # Final result\n",
        "    df[\"result\"] = (\n",
        "        df[[f\"{subject}_pass\" for subject in subjects]]\n",
        "        .all(axis=1) & df[\"overall_pass\"]\n",
        "    )\n",
        "\n",
        "    # Convert boolean to label\n",
        "    df[\"result\"] = df[\"result\"].map({True: \"PASS\", False: \"FAIL\"})\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# Execute Phase 3\n",
        "df = classify_pass_fail(df)\n",
        "\n",
        "print(\"PHASE 3 COMPLETED SUCCESSFULLY\")\n",
        "\n",
        "# Preview results\n",
        "df[[\n",
        "    \"final_weighted_score\",\n",
        "    \"result\"\n",
        "]].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "BQtnAVSjC7hE",
        "outputId": "27b450d6-30d9-4495-c1e4-994492505171"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "closing parenthesis ']' does not match opening parenthesis '(' on line 61 (685558388.py, line 63)",
          "output_type": "error",
          "traceback": [
            "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mfailed_subjects + near_fail_subjects]].head()\u001b[39m\n                                        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m closing parenthesis ']' does not match opening parenthesis '(' on line 61\n"
          ]
        }
      ],
      "source": [
        "# ==============================\n",
        "# PHASE 4: RISK ANALYSIS & FAILURE DIAGNOSIS\n",
        "# ==============================\n",
        "\n",
        "def calculate_risk_and_reason(row):\n",
        "    failed_subjects = []\n",
        "    near_fail_subjects = []\n",
        "\n",
        "    for subject in subjects:\n",
        "        score = row[f\"{subject}_total\"]\n",
        "\n",
        "        if score < PASSING_PERCENTAGE:\n",
        "            failed_subjects.append(subject)\n",
        "        elif PASSING_PERCENTAGE <= score < PASSING_PERCENTAGE + 10:\n",
        "            near_fail_subjects.append(subject)\n",
        "\n",
        "    # Base risk from final score\n",
        "    if row[\"final_weighted_score\"] < PASSING_PERCENTAGE:\n",
        "        risk = 80\n",
        "    elif row[\"final_weighted_score\"] < PASSING_PERCENTAGE + 10:\n",
        "        risk = 60\n",
        "    elif row[\"final_weighted_score\"] < PASSING_PERCENTAGE + 20:\n",
        "        risk = 40\n",
        "    else:\n",
        "        risk = 20\n",
        "\n",
        "    # Increase risk for failed or weak subjects\n",
        "    risk += len(failed_subjects) * 10\n",
        "    risk += len(near_fail_subjects) * 5\n",
        "\n",
        "    # Attendance impact\n",
        "    if row[\"attendance_score\"] < 6:\n",
        "        risk += 10\n",
        "\n",
        "    risk = min(risk, 100)\n",
        "\n",
        "    # Humanâ€‘readable reason text\n",
        "    reason_parts = []\n",
        "    if failed_subjects:\n",
        "        reason_parts.append(\"Failed subjects: \" + \", \".join(failed_subjects))\n",
        "    if near_fail_subjects:\n",
        "        reason_parts.append(\"Weak performance in: \" + \", \".join(near_fail_subjects))\n",
        "    if row[\"attendance_score\"] < 6:\n",
        "        reason_parts.append(\"Low attendance may have contributed\")\n",
        "    if not reason_parts:\n",
        "        reason_parts.append(\"No specific failure reason identified â€“ keep up the good work\")\n",
        "\n",
        "    # Mentorâ€‘like improvement tips\n",
        "    tips = []\n",
        "    if failed_subjects:\n",
        "        tips.append(\"Seek help from a mentor or tutor on \" + \", \".join(failed_subjects))\n",
        "    if near_fail_subjects:\n",
        "        tips.append(\"Strengthen weak areas: \" + \", \".join(near_fail_subjects))\n",
        "    if row[\"attendance_score\"] < 6:\n",
        "        tips.append(\"Improve attendance; it influences the weighted score\")\n",
        "    tips.append(\"Maintain consistency and practice regularly\")\n",
        "\n",
        "    return pd.Series({\n",
        "        \"risk_percent\": risk,\n",
        "        \"failed_subjects\": failed_subjects if failed_subjects else [\"None\"],\n",
        "        \"improvement_areas\": (\n",
        "\n",
        "            failed_subjects + near_fail_subjects]].head()\n",
        "\n",
        "            if (failed_subjects or near_fail_subjects)    \"mentor_tips\"\n",
        "\n",
        "            else [\"Maintain consistency\"]    \"reason_text\",\n",
        "\n",
        "        ),    \"improvement_areas\",\n",
        "\n",
        "        \"reason_text\": \" | \".join(reason_parts),    \"failed_subjects\",\n",
        "\n",
        "        \"mentor_tips\": \" | \".join(tips)    \"risk_percent\",\n",
        "\n",
        "    })    \"result\",\n",
        "\n",
        "df[[\n",
        "\n",
        "# Preview\n",
        "\n",
        "# Apply Phase 4\n",
        "\n",
        "df[[\"risk_percent\", \"failed_subjects\", \"improvement_areas\", \"reason_text\", \"mentor_tips\"]] = df.apply(print(\"PHASE 4 COMPLETED SUCCESSFULLY\")\n",
        "\n",
        "    calculate_risk_and_reason, axis=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "6iHbzePaDow-",
        "outputId": "10293cd6-3237-42e2-fab4-dcf5edac5358"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PHASE 5 COMPLETED SUCCESSFULLY\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0    {'Final Result': 'PASS', 'Risk of Failing Agai...\n",
              "1    {'Final Result': 'FAIL', 'Risk of Failing Agai...\n",
              "2    {'Final Result': 'FAIL', 'Risk of Failing Agai...\n",
              "3    {'Final Result': 'FAIL', 'Risk of Failing Agai...\n",
              "4    {'Final Result': 'FAIL', 'Risk of Failing Agai...\n",
              "Name: final_output, dtype: object"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ==============================\n",
        "# PHASE 5: FINAL OUTPUT GENERATION\n",
        "# ==============================\n",
        "\n",
        "def generate_final_output(row):\n",
        "    output = {\n",
        "        \"Final Result\": row[\"result\"],\n",
        "        \"Risk of Failing Again (%)\": row[\"risk_percent\"],\n",
        "        \"Reason of Failure\": row.get(\"reason_text\",\n",
        "                                    row[\"failed_subjects\"] if row[\"result\"] == \"FAIL\" else \"None\"),\n",
        "        \"Improvement Suggestions\": row.get(\"mentor_tips\", row[\"improvement_areas\"])\n",
        "    }\n",
        "    return output\n",
        "\n",
        "\n",
        "# Apply Phase 5\n",
        "df[\"final_output\"] = df.apply(generate_final_output, axis=1)\n",
        "\n",
        "print(\"PHASE 5 COMPLETED SUCCESSFULLY\")\n",
        "\n",
        "# Show sample final outputs\n",
        "df[\"final_output\"].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oDX55mugwl3",
        "outputId": "0102a348-a473-443b-bf8b-5b68c8132a7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature columns used:\n",
            "['maths_total', 'science_total', 'english_total', 'hindi_total', 'social_science_total', 'computer_science_total', 'attendance_score', 'final_weighted_score']\n",
            "\n",
            "Target distribution:\n",
            "result_ml\n",
            "0    9482\n",
            "1     518\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# STEP 6.1: PREPARE DATA FOR ML\n",
        "\n",
        "# Convert target to numeric\n",
        "df[\"result_ml\"] = df[\"result\"].map({\"PASS\": 1, \"FAIL\": 0})\n",
        "\n",
        "# Select feature columns\n",
        "feature_cols = (\n",
        "    [f\"{s}_total\" for s in subjects]\n",
        "    + [\"attendance_score\", \"final_weighted_score\"]\n",
        ")\n",
        "\n",
        "X = df[feature_cols]\n",
        "y = df[\"result_ml\"]\n",
        "\n",
        "print(\"Feature columns used:\")\n",
        "print(feature_cols)\n",
        "print(\"\\nTarget distribution:\")\n",
        "print(y.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-J5tGfKchSm_",
        "outputId": "58c63881-bfb1-45d0-f0da-22ab14e4c4bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training samples: 8000\n",
            "Testing samples: 2000\n"
          ]
        }
      ],
      "source": [
        "# STEP 6.2: TRAIN-TEST SPLIT\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(\"Training samples:\", X_train.shape[0])\n",
        "print(\"Testing samples:\", X_test.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUGgoR5_hdI6",
        "outputId": "1ed92526-9e35-4a86-f50b-3880db18575d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model training completed\n"
          ]
        }
      ],
      "source": [
        "# STEP 6.3: MODEL TRAINING\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Model training completed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MH7mfeWhil3",
        "outputId": "deb47277-e8b1-459d-8801-964e89081a95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 95.5 %\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1880   16]\n",
            " [  74   30]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.98      1896\n",
            "           1       0.65      0.29      0.40       104\n",
            "\n",
            "    accuracy                           0.95      2000\n",
            "   macro avg       0.81      0.64      0.69      2000\n",
            "weighted avg       0.95      0.95      0.95      2000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# STEP 6.4: MODEL TESTING & EVALUATION\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", round(accuracy * 100, 2), \"%\")\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "print(\"\\nClassification Report:\\n\", report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NT0JEkrkh8Oo",
        "outputId": "df65a2f8-5419-4a3c-fa5b-be90b4488380"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved as pass_fail_model.pkl\n"
          ]
        }
      ],
      "source": [
        "# STEP 7.1: SAVE MODEL\n",
        "\n",
        "import joblib\n",
        "\n",
        "joblib.dump(model, \"pass_fail_model.pkl\")\n",
        "print(\"Model saved as pass_fail_model.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNuK8NeniJUX",
        "outputId": "0476a5bc-6591-4fe9-a803-223bd9926cf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "model = joblib.load(\"pass_fail_model.pkl\")\n",
        "\n",
        "subjects = [\n",
        "    \"maths\", \"science\", \"english\",\n",
        "    \"hindi\", \"social_science\", \"computer_science\"\n",
        "]\n",
        "\n",
        "st.title(\"ðŸŽ“ Student Pass/Fail Predictor\")\n",
        "\n",
        "input_data = {}\n",
        "\n",
        "for subject in subjects:\n",
        "    input_data[f\"{subject}_total\"] = st.number_input(\n",
        "        f\"{subject.capitalize()} Total Marks\", 0, 100, 50\n",
        "    )\n",
        "\n",
        "attendance = st.slider(\"Attendance Score (0â€“10)\", 0.0, 10.0, 7.0)\n",
        "input_data[\"attendance_score\"] = attendance\n",
        "\n",
        "input_data[\"final_weighted_score\"] = (\n",
        "    0.85 * sum(input_data[f\"{s}_total\"] for s in subjects) / 6\n",
        "    + 0.15 * (attendance * 10)\n",
        ")\n",
        "\n",
        "if st.button(\"Predict\"):\n",
        "    df_input = pd.DataFrame([input_data])\n",
        "    pred = model.predict(df_input)[0]\n",
        "    prob = model.predict_proba(df_input)[0][1]\n",
        "\n",
        "    st.subheader(\"Result\")\n",
        "    st.write(\"PASS âœ…\" if pred == 1 else \"FAIL âŒ\")\n",
        "    st.write(\"Risk of failing again:\", round((1 - prob) * 100, 2), \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ulv6HOHmiW-d",
        "outputId": "e5896afa-f32f-4b55-e3ef-9452e51a17d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.54.0-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.5.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting altair!=5.4.0,!=5.4.1,<7,>=4.0 (from streamlit)\n",
            "  Downloading altair-6.0.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting blinker<2,>=1.5.0 (from streamlit)\n",
            "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting cachetools<7,>=5.5 (from streamlit)\n",
            "  Downloading cachetools-6.2.6-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting click<9,>=7.0 (from streamlit)\n",
            "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading gitpython-3.1.46-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in C:\\Users\\hiral\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages (from streamlit) (2.4.2)\n",
            "Requirement already satisfied: packaging>=20 in C:\\Users\\hiral\\AppData\\Roaming\\Python\\Python314\\site-packages (from streamlit) (26.0)\n",
            "Collecting pandas<3,>=1.4.0 (from streamlit)\n",
            "  Downloading pandas-2.3.3-cp314-cp314-win_amd64.whl.metadata (19 kB)\n",
            "Collecting pillow<13,>=7.1.0 (from streamlit)\n",
            "  Downloading pillow-12.1.1-cp314-cp314-win_amd64.whl.metadata (9.0 kB)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting protobuf<7,>=3.20 (from streamlit)\n",
            "  Downloading protobuf-6.33.5-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
            "Collecting pyarrow>=7.0 (from streamlit)\n",
            "  Downloading pyarrow-23.0.1-cp314-cp314-win_amd64.whl.metadata (3.1 kB)\n",
            "Collecting requests<3,>=2.27 (from streamlit)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting tenacity<10,>=8.1.0 (from streamlit)\n",
            "  Downloading tenacity-9.1.4-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting toml<2,>=0.10.1 (from streamlit)\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in C:\\Users\\hiral\\AppData\\Roaming\\Python\\Python314\\site-packages (from streamlit) (6.5.4)\n",
            "Collecting typing-extensions<5,>=4.10.0 (from streamlit)\n",
            "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-win_amd64.whl.metadata (44 kB)\n",
            "Collecting jinja2 (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting jsonschema>=3.0 (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit)\n",
            "  Downloading jsonschema-4.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting narwhals>=1.27.1 (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit)\n",
            "  Downloading narwhals-2.16.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: colorama in C:\\Users\\hiral\\AppData\\Roaming\\Python\\Python314\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in C:\\Users\\hiral\\AppData\\Roaming\\Python\\Python314\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Collecting pytz>=2020.1 (from pandas<3,>=1.4.0->streamlit)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: tzdata>=2022.7 in C:\\Users\\hiral\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.3)\n",
            "Collecting charset_normalizer<4,>=2 (from requests<3,>=2.27->streamlit)\n",
            "  Downloading charset_normalizer-3.4.4-cp314-cp314-win_amd64.whl.metadata (38 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<3,>=2.27->streamlit)\n",
            "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.27->streamlit)\n",
            "  Downloading urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<3,>=2.27->streamlit)\n",
            "  Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting PyYAML>=5.1 (from pyngrok)\n",
            "  Downloading pyyaml-6.0.3-cp314-cp314-win_amd64.whl.metadata (2.4 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit)\n",
            "  Downloading markupsafe-3.0.3-cp314-cp314-win_amd64.whl.metadata (2.8 kB)\n",
            "Collecting attrs>=22.2.0 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit)\n",
            "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit)\n",
            "  Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit)\n",
            "  Downloading referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.25.0 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit)\n",
            "  Downloading rpds_py-0.30.0-cp314-cp314-win_amd64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in C:\\Users\\hiral\\AppData\\Roaming\\Python\\Python314\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.54.0-py3-none-any.whl (9.1 MB)\n",
            "   ---------------------------------------- 0.0/9.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/9.1 MB ? eta -:--:--\n",
            "   - -------------------------------------- 0.3/9.1 MB ? eta -:--:--\n",
            "   -- ------------------------------------- 0.5/9.1 MB 2.4 MB/s eta 0:00:04\n",
            "   ---- ----------------------------------- 1.0/9.1 MB 1.7 MB/s eta 0:00:05\n",
            "   ----- ---------------------------------- 1.3/9.1 MB 1.9 MB/s eta 0:00:05\n",
            "   -------- ------------------------------- 1.8/9.1 MB 2.0 MB/s eta 0:00:04\n",
            "   ----------- ---------------------------- 2.6/9.1 MB 2.2 MB/s eta 0:00:04\n",
            "   ------------- -------------------------- 3.1/9.1 MB 2.2 MB/s eta 0:00:03\n",
            "   ---------------- ----------------------- 3.7/9.1 MB 2.2 MB/s eta 0:00:03\n",
            "   ----------------- ---------------------- 3.9/9.1 MB 2.2 MB/s eta 0:00:03\n",
            "   -------------------- ------------------- 4.7/9.1 MB 2.3 MB/s eta 0:00:02\n",
            "   ------------------------ --------------- 5.5/9.1 MB 2.4 MB/s eta 0:00:02\n",
            "   -------------------------- ------------- 6.0/9.1 MB 2.5 MB/s eta 0:00:02\n",
            "   ---------------------------- ----------- 6.6/9.1 MB 2.4 MB/s eta 0:00:02\n",
            "   ----------------------------- ---------- 6.8/9.1 MB 2.4 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 7.3/9.1 MB 2.4 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 7.9/9.1 MB 2.4 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 8.1/9.1 MB 2.3 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 8.4/9.1 MB 2.3 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 8.4/9.1 MB 2.3 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 8.4/9.1 MB 2.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 9.1/9.1 MB 2.1 MB/s  0:00:04\n",
            "Downloading altair-6.0.0-py3-none-any.whl (795 kB)\n",
            "   ---------------------------------------- 0.0/795.4 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/795.4 kB ? eta -:--:--\n",
            "   ------------- -------------------------- 262.1/795.4 kB ? eta -:--:--\n",
            "   ------------------------- ------------ 524.3/795.4 kB 911.8 kB/s eta 0:00:01\n",
            "   ---------------------------------------- 795.4/795.4 kB 953.9 kB/s  0:00:00\n",
            "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
            "Downloading cachetools-6.2.6-py3-none-any.whl (11 kB)\n",
            "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
            "Downloading gitpython-3.1.46-py3-none-any.whl (208 kB)\n",
            "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
            "Downloading pandas-2.3.3-cp314-cp314-win_amd64.whl (11.1 MB)\n",
            "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.3/11.1 MB ? eta -:--:--\n",
            "   -- ------------------------------------- 0.8/11.1 MB 1.7 MB/s eta 0:00:06\n",
            "   --- ------------------------------------ 1.0/11.1 MB 1.6 MB/s eta 0:00:07\n",
            "   ---- ----------------------------------- 1.3/11.1 MB 1.7 MB/s eta 0:00:06\n",
            "   ----- ---------------------------------- 1.6/11.1 MB 1.5 MB/s eta 0:00:07\n",
            "   ------- -------------------------------- 2.1/11.1 MB 1.6 MB/s eta 0:00:06\n",
            "   --------- ------------------------------ 2.6/11.1 MB 1.8 MB/s eta 0:00:05\n",
            "   ------------ --------------------------- 3.4/11.1 MB 2.0 MB/s eta 0:00:04\n",
            "   ------------- -------------------------- 3.7/11.1 MB 2.0 MB/s eta 0:00:04\n",
            "   -------------- ------------------------- 3.9/11.1 MB 2.0 MB/s eta 0:00:04\n",
            "   --------------- ------------------------ 4.2/11.1 MB 2.0 MB/s eta 0:00:04\n",
            "   ---------------- ----------------------- 4.7/11.1 MB 2.0 MB/s eta 0:00:04\n",
            "   ----------------- ---------------------- 5.0/11.1 MB 1.9 MB/s eta 0:00:04\n",
            "   ------------------ --------------------- 5.2/11.1 MB 1.9 MB/s eta 0:00:04\n",
            "   ------------------ --------------------- 5.2/11.1 MB 1.9 MB/s eta 0:00:04\n",
            "   --------------------- ------------------ 6.0/11.1 MB 1.8 MB/s eta 0:00:03\n",
            "   --------------------- ------------------ 6.0/11.1 MB 1.8 MB/s eta 0:00:03\n",
            "   ---------------------- ----------------- 6.3/11.1 MB 1.7 MB/s eta 0:00:03\n",
            "   ----------------------- ---------------- 6.6/11.1 MB 1.7 MB/s eta 0:00:03\n",
            "   ------------------------ --------------- 6.8/11.1 MB 1.6 MB/s eta 0:00:03\n",
            "   ------------------------- -------------- 7.1/11.1 MB 1.6 MB/s eta 0:00:03\n",
            "   -------------------------- ------------- 7.3/11.1 MB 1.6 MB/s eta 0:00:03\n",
            "   --------------------------- ------------ 7.6/11.1 MB 1.6 MB/s eta 0:00:03\n",
            "   ---------------------------- ----------- 7.9/11.1 MB 1.6 MB/s eta 0:00:03\n",
            "   ----------------------------- ---------- 8.1/11.1 MB 1.6 MB/s eta 0:00:02\n",
            "   ------------------------------ --------- 8.4/11.1 MB 1.5 MB/s eta 0:00:02\n",
            "   ------------------------------ --------- 8.4/11.1 MB 1.5 MB/s eta 0:00:02\n",
            "   ------------------------------ --------- 8.4/11.1 MB 1.5 MB/s eta 0:00:02\n",
            "   -------------------------------- ------- 8.9/11.1 MB 1.5 MB/s eta 0:00:02\n",
            "   --------------------------------- ------ 9.2/11.1 MB 1.5 MB/s eta 0:00:02\n",
            "   --------------------------------- ------ 9.4/11.1 MB 1.5 MB/s eta 0:00:02\n",
            "   --------------------------------- ------ 9.4/11.1 MB 1.5 MB/s eta 0:00:02\n",
            "   ----------------------------------- ---- 10.0/11.1 MB 1.4 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 10.0/11.1 MB 1.4 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 10.0/11.1 MB 1.4 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 10.2/11.1 MB 1.3 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 10.5/11.1 MB 1.3 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 10.5/11.1 MB 1.3 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 10.5/11.1 MB 1.3 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 10.7/11.1 MB 1.3 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 10.7/11.1 MB 1.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 11.1/11.1 MB 1.2 MB/s  0:00:08\n",
            "Downloading pillow-12.1.1-cp314-cp314-win_amd64.whl (7.2 MB)\n",
            "   ---------------------------------------- 0.0/7.2 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/7.2 MB ? eta -:--:--\n",
            "   - -------------------------------------- 0.3/7.2 MB ? eta -:--:--\n",
            "   - -------------------------------------- 0.3/7.2 MB ? eta -:--:--\n",
            "   -- ------------------------------------- 0.5/7.2 MB 625.5 kB/s eta 0:00:11\n",
            "   -- ------------------------------------- 0.5/7.2 MB 625.5 kB/s eta 0:00:11\n",
            "   ---- ----------------------------------- 0.8/7.2 MB 561.7 kB/s eta 0:00:12\n",
            "   ----- ---------------------------------- 1.0/7.2 MB 700.7 kB/s eta 0:00:09\n",
            "   ------- -------------------------------- 1.3/7.2 MB 815.7 kB/s eta 0:00:08\n",
            "   -------- ------------------------------- 1.6/7.2 MB 911.2 kB/s eta 0:00:07\n",
            "   ---------- ----------------------------- 1.8/7.2 MB 974.0 kB/s eta 0:00:06\n",
            "   ----------- ---------------------------- 2.1/7.2 MB 978.4 kB/s eta 0:00:06\n",
            "   ------------- -------------------------- 2.4/7.2 MB 1.0 MB/s eta 0:00:05\n",
            "   ---------------- ----------------------- 2.9/7.2 MB 1.1 MB/s eta 0:00:04\n",
            "   ---------------- ----------------------- 2.9/7.2 MB 1.1 MB/s eta 0:00:04\n",
            "   ----------------- ---------------------- 3.1/7.2 MB 1.1 MB/s eta 0:00:04\n",
            "   -------------------- ------------------- 3.7/7.2 MB 1.1 MB/s eta 0:00:04\n",
            "   --------------------- ------------------ 3.9/7.2 MB 1.2 MB/s eta 0:00:03\n",
            "   ----------------------- ---------------- 4.2/7.2 MB 1.2 MB/s eta 0:00:03\n",
            "   ------------------------ --------------- 4.5/7.2 MB 1.2 MB/s eta 0:00:03\n",
            "   -------------------------- ------------- 4.7/7.2 MB 1.2 MB/s eta 0:00:03\n",
            "   --------------------------- ------------ 5.0/7.2 MB 1.2 MB/s eta 0:00:02\n",
            "   ----------------------------- ---------- 5.2/7.2 MB 1.2 MB/s eta 0:00:02\n",
            "   ------------------------------ --------- 5.5/7.2 MB 1.2 MB/s eta 0:00:02\n",
            "   -------------------------------- ------- 5.8/7.2 MB 1.2 MB/s eta 0:00:02\n",
            "   --------------------------------- ------ 6.0/7.2 MB 1.2 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 6.0/7.2 MB 1.2 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 6.3/7.2 MB 1.2 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 6.6/7.2 MB 1.2 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 6.8/7.2 MB 1.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 7.2/7.2 MB 1.2 MB/s  0:00:06\n",
            "Downloading protobuf-6.33.5-cp310-abi3-win_amd64.whl (437 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "   ---------------------------------------- 0.0/6.9 MB ? eta -:--:--\n",
            "   - -------------------------------------- 0.3/6.9 MB ? eta -:--:--\n",
            "   --- ------------------------------------ 0.5/6.9 MB 1.9 MB/s eta 0:00:04\n",
            "   ------ --------------------------------- 1.0/6.9 MB 1.6 MB/s eta 0:00:04\n",
            "   ------ --------------------------------- 1.0/6.9 MB 1.6 MB/s eta 0:00:04\n",
            "   --------- ------------------------------ 1.6/6.9 MB 1.4 MB/s eta 0:00:04\n",
            "   ---------- ----------------------------- 1.8/6.9 MB 1.4 MB/s eta 0:00:04\n",
            "   ------------ --------------------------- 2.1/6.9 MB 1.5 MB/s eta 0:00:04\n",
            "   --------------- ------------------------ 2.6/6.9 MB 1.5 MB/s eta 0:00:03\n",
            "   ---------------- ----------------------- 2.9/6.9 MB 1.6 MB/s eta 0:00:03\n",
            "   ------------------- -------------------- 3.4/6.9 MB 1.6 MB/s eta 0:00:03\n",
            "   ---------------------- ----------------- 3.9/6.9 MB 1.7 MB/s eta 0:00:02\n",
            "   ------------------------- -------------- 4.5/6.9 MB 1.8 MB/s eta 0:00:02\n",
            "   ---------------------------- ----------- 5.0/6.9 MB 1.8 MB/s eta 0:00:02\n",
            "   ------------------------------ --------- 5.2/6.9 MB 1.8 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 5.8/6.9 MB 1.8 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 6.0/6.9 MB 1.8 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 6.3/6.9 MB 1.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------  6.8/6.9 MB 1.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 6.9/6.9 MB 1.8 MB/s  0:00:03\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Downloading charset_normalizer-3.4.4-cp314-cp314-win_amd64.whl (107 kB)\n",
            "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
            "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
            "Downloading tenacity-9.1.4-py3-none-any.whl (28 kB)\n",
            "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Downloading urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
            "Downloading watchdog-6.0.0-py3-none-win_amd64.whl (79 kB)\n",
            "Downloading pyngrok-7.5.0-py3-none-any.whl (24 kB)\n",
            "Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading jsonschema-4.26.0-py3-none-any.whl (90 kB)\n",
            "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
            "Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
            "Downloading markupsafe-3.0.3-cp314-cp314-win_amd64.whl (15 kB)\n",
            "Downloading narwhals-2.16.0-py3-none-any.whl (443 kB)\n",
            "Downloading pyarrow-23.0.1-cp314-cp314-win_amd64.whl (28.2 MB)\n",
            "   ---------------------------------------- 0.0/28.2 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.3/28.2 MB ? eta -:--:--\n",
            "   - -------------------------------------- 0.8/28.2 MB 2.2 MB/s eta 0:00:13\n",
            "   - -------------------------------------- 1.0/28.2 MB 2.2 MB/s eta 0:00:13\n",
            "   -- ------------------------------------- 1.6/28.2 MB 2.1 MB/s eta 0:00:13\n",
            "   -- ------------------------------------- 2.1/28.2 MB 2.1 MB/s eta 0:00:13\n",
            "   --- ------------------------------------ 2.4/28.2 MB 2.1 MB/s eta 0:00:13\n",
            "   ---- ----------------------------------- 2.9/28.2 MB 2.1 MB/s eta 0:00:13\n",
            "   ---- ----------------------------------- 3.1/28.2 MB 2.0 MB/s eta 0:00:13\n",
            "   ----- ---------------------------------- 3.7/28.2 MB 2.0 MB/s eta 0:00:13\n",
            "   ----- ---------------------------------- 3.9/28.2 MB 1.9 MB/s eta 0:00:13\n",
            "   ----- ---------------------------------- 4.2/28.2 MB 1.9 MB/s eta 0:00:13\n",
            "   ------ --------------------------------- 4.5/28.2 MB 1.9 MB/s eta 0:00:13\n",
            "   ------ --------------------------------- 4.7/28.2 MB 1.9 MB/s eta 0:00:13\n",
            "   ------- -------------------------------- 5.2/28.2 MB 1.8 MB/s eta 0:00:13\n",
            "   ------- -------------------------------- 5.5/28.2 MB 1.7 MB/s eta 0:00:14\n",
            "   -------- ------------------------------- 6.0/28.2 MB 1.8 MB/s eta 0:00:13\n",
            "   --------- ------------------------------ 6.6/28.2 MB 1.8 MB/s eta 0:00:12\n",
            "   ---------- ----------------------------- 7.1/28.2 MB 1.9 MB/s eta 0:00:12\n",
            "   ---------- ----------------------------- 7.3/28.2 MB 1.9 MB/s eta 0:00:12\n",
            "   ----------- ---------------------------- 7.9/28.2 MB 1.9 MB/s eta 0:00:11\n",
            "   ----------- ---------------------------- 8.1/28.2 MB 1.9 MB/s eta 0:00:11\n",
            "   ----------- ---------------------------- 8.4/28.2 MB 1.8 MB/s eta 0:00:11\n",
            "   ------------ --------------------------- 8.9/28.2 MB 1.8 MB/s eta 0:00:11\n",
            "   ------------- -------------------------- 9.4/28.2 MB 1.9 MB/s eta 0:00:11\n",
            "   ------------- -------------------------- 9.7/28.2 MB 1.9 MB/s eta 0:00:10\n",
            "   -------------- ------------------------- 10.2/28.2 MB 1.9 MB/s eta 0:00:10\n",
            "   --------------- ------------------------ 11.0/28.2 MB 1.9 MB/s eta 0:00:09\n",
            "   --------------- ------------------------ 11.3/28.2 MB 1.9 MB/s eta 0:00:09\n",
            "   ---------------- ----------------------- 11.5/28.2 MB 1.9 MB/s eta 0:00:09\n",
            "   ----------------- ---------------------- 12.1/28.2 MB 1.9 MB/s eta 0:00:09\n",
            "   ----------------- ---------------------- 12.6/28.2 MB 1.9 MB/s eta 0:00:09\n",
            "   ------------------ --------------------- 13.1/28.2 MB 1.9 MB/s eta 0:00:08\n",
            "   ------------------- -------------------- 13.6/28.2 MB 2.0 MB/s eta 0:00:08\n",
            "   -------------------- ------------------- 14.2/28.2 MB 2.0 MB/s eta 0:00:08\n",
            "   --------------------- ------------------ 14.9/28.2 MB 2.0 MB/s eta 0:00:07\n",
            "   --------------------- ------------------ 15.2/28.2 MB 2.0 MB/s eta 0:00:07\n",
            "   ---------------------- ----------------- 15.7/28.2 MB 2.0 MB/s eta 0:00:07\n",
            "   ----------------------- ---------------- 16.5/28.2 MB 2.0 MB/s eta 0:00:06\n",
            "   ----------------------- ---------------- 16.8/28.2 MB 2.1 MB/s eta 0:00:06\n",
            "   ------------------------ --------------- 17.0/28.2 MB 2.0 MB/s eta 0:00:06\n",
            "   ------------------------ --------------- 17.6/28.2 MB 2.0 MB/s eta 0:00:06\n",
            "   ------------------------- -------------- 18.1/28.2 MB 2.0 MB/s eta 0:00:05\n",
            "   -------------------------- ------------- 18.6/28.2 MB 2.1 MB/s eta 0:00:05\n",
            "   --------------------------- ------------ 19.1/28.2 MB 2.1 MB/s eta 0:00:05\n",
            "   --------------------------- ------------ 19.7/28.2 MB 2.1 MB/s eta 0:00:05\n",
            "   --------------------------- ------------ 19.7/28.2 MB 2.1 MB/s eta 0:00:05\n",
            "   ---------------------------- ----------- 19.9/28.2 MB 2.0 MB/s eta 0:00:05\n",
            "   ---------------------------- ----------- 19.9/28.2 MB 2.0 MB/s eta 0:00:05\n",
            "   ---------------------------- ----------- 20.2/28.2 MB 1.9 MB/s eta 0:00:05\n",
            "   ---------------------------- ----------- 20.4/28.2 MB 1.9 MB/s eta 0:00:05\n",
            "   ----------------------------- ---------- 21.0/28.2 MB 1.9 MB/s eta 0:00:04\n",
            "   ------------------------------ --------- 21.2/28.2 MB 1.9 MB/s eta 0:00:04\n",
            "   ------------------------------ --------- 21.8/28.2 MB 1.9 MB/s eta 0:00:04\n",
            "   ------------------------------- -------- 22.3/28.2 MB 2.0 MB/s eta 0:00:04\n",
            "   ------------------------------- -------- 22.5/28.2 MB 2.0 MB/s eta 0:00:03\n",
            "   -------------------------------- ------- 22.8/28.2 MB 1.9 MB/s eta 0:00:03\n",
            "   -------------------------------- ------- 22.8/28.2 MB 1.9 MB/s eta 0:00:03\n",
            "   --------------------------------- ------ 23.3/28.2 MB 1.9 MB/s eta 0:00:03\n",
            "   --------------------------------- ------ 23.6/28.2 MB 1.9 MB/s eta 0:00:03\n",
            "   --------------------------------- ------ 23.9/28.2 MB 1.9 MB/s eta 0:00:03\n",
            "   ---------------------------------- ----- 24.4/28.2 MB 1.9 MB/s eta 0:00:03\n",
            "   ---------------------------------- ----- 24.6/28.2 MB 1.9 MB/s eta 0:00:02\n",
            "   ----------------------------------- ---- 25.2/28.2 MB 1.9 MB/s eta 0:00:02\n",
            "   ------------------------------------ --- 25.7/28.2 MB 1.9 MB/s eta 0:00:02\n",
            "   ------------------------------------ --- 26.0/28.2 MB 1.9 MB/s eta 0:00:02\n",
            "   ------------------------------------- -- 26.5/28.2 MB 1.9 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 26.7/28.2 MB 1.9 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 27.0/28.2 MB 1.9 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 27.5/28.2 MB 1.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  28.0/28.2 MB 1.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 28.2/28.2 MB 1.9 MB/s  0:00:14\n",
            "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Downloading pyyaml-6.0.3-cp314-cp314-win_amd64.whl (156 kB)\n",
            "Downloading referencing-0.37.0-py3-none-any.whl (26 kB)\n",
            "Downloading rpds_py-0.30.0-cp314-cp314-win_amd64.whl (228 kB)\n",
            "Installing collected packages: pytz, watchdog, urllib3, typing-extensions, toml, tenacity, smmap, rpds-py, PyYAML, pyarrow, protobuf, pillow, narwhals, MarkupSafe, idna, click, charset_normalizer, certifi, cachetools, blinker, attrs, requests, referencing, pyngrok, pandas, jinja2, gitdb, pydeck, jsonschema-specifications, gitpython, jsonschema, altair, streamlit\n",
            "\n",
            "   ----------------------------------------  0/33 [pytz]\n",
            "   ----------------------------------------  0/33 [pytz]\n",
            "   -- -------------------------------------  2/33 [urllib3]\n",
            "   --- ------------------------------------  3/33 [typing-extensions]\n",
            "   --------- ------------------------------  8/33 [PyYAML]\n",
            "   ---------- -----------------------------  9/33 [pyarrow]\n",
            "   ---------- -----------------------------  9/33 [pyarrow]\n",
            "   ---------- -----------------------------  9/33 [pyarrow]\n",
            "   ---------- -----------------------------  9/33 [pyarrow]\n",
            "   ---------- -----------------------------  9/33 [pyarrow]\n",
            "   ---------- -----------------------------  9/33 [pyarrow]\n",
            "   ---------- -----------------------------  9/33 [pyarrow]\n",
            "   ---------- -----------------------------  9/33 [pyarrow]\n",
            "   ------------ --------------------------- 10/33 [protobuf]\n",
            "   ------------ --------------------------- 10/33 [protobuf]\n",
            "   ------------- -------------------------- 11/33 [pillow]\n",
            "   ------------- -------------------------- 11/33 [pillow]\n",
            "   ------------- -------------------------- 11/33 [pillow]\n",
            "   -------------- ------------------------- 12/33 [narwhals]\n",
            "   -------------- ------------------------- 12/33 [narwhals]\n",
            "   -------------- ------------------------- 12/33 [narwhals]\n",
            "   -------------- ------------------------- 12/33 [narwhals]\n",
            "   -------------- ------------------------- 12/33 [narwhals]\n",
            "   ---------------- ----------------------- 14/33 [idna]\n",
            "   ------------------- -------------------- 16/33 [charset_normalizer]\n",
            "   ------------------------ --------------- 20/33 [attrs]\n",
            "   -------------------------- ------------- 22/33 [referencing]\n",
            "  Attempting uninstall: pandas\n",
            "   -------------------------- ------------- 22/33 [referencing]\n",
            "    Found existing installation: pandas 3.0.1\n",
            "   -------------------------- ------------- 22/33 [referencing]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "    Uninstalling pandas-3.0.1:\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "      Successfully uninstalled pandas-3.0.1\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ----------------------------- ---------- 24/33 [pandas]\n",
            "   ------------------------------ --------- 25/33 [jinja2]\n",
            "   ------------------------------ --------- 25/33 [jinja2]\n",
            "   -------------------------------- ------- 27/33 [pydeck]\n",
            "   --------------------------------- ------ 28/33 [jsonschema-specifications]\n",
            "   ----------------------------------- ---- 29/33 [gitpython]\n",
            "   ------------------------------------ --- 30/33 [jsonschema]\n",
            "   ------------------------------------- -- 31/33 [altair]\n",
            "   ------------------------------------- -- 31/33 [altair]\n",
            "   -------------------------------------- - 32/33 [streamlit]\n",
            "   -------------------------------------- - 32/33 [streamlit]\n",
            "   -------------------------------------- - 32/33 [streamlit]\n",
            "   -------------------------------------- - 32/33 [streamlit]\n",
            "   -------------------------------------- - 32/33 [streamlit]\n",
            "   -------------------------------------- - 32/33 [streamlit]\n",
            "   -------------------------------------- - 32/33 [streamlit]\n",
            "   -------------------------------------- - 32/33 [streamlit]\n",
            "   -------------------------------------- - 32/33 [streamlit]\n",
            "   ---------------------------------------- 33/33 [streamlit]\n",
            "\n",
            "Successfully installed MarkupSafe-3.0.3 PyYAML-6.0.3 altair-6.0.0 attrs-25.4.0 blinker-1.9.0 cachetools-6.2.6 certifi-2026.1.4 charset_normalizer-3.4.4 click-8.3.1 gitdb-4.0.12 gitpython-3.1.46 idna-3.11 jinja2-3.1.6 jsonschema-4.26.0 jsonschema-specifications-2025.9.1 narwhals-2.16.0 pandas-2.3.3 pillow-12.1.1 protobuf-6.33.5 pyarrow-23.0.1 pydeck-0.9.1 pyngrok-7.5.0 pytz-2025.2 referencing-0.37.0 requests-2.32.5 rpds-py-0.30.0 smmap-5.0.2 streamlit-1.54.0 tenacity-9.1.4 toml-0.10.2 typing-extensions-4.15.0 urllib3-2.6.3 watchdog-6.0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\hiral\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\~andas'.\n",
            "  You can safely remove it manually.\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "lUfHFuU4ighu",
        "outputId": "108b66d0-9dab-41b5-e339-df2df6d2cb36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                                    \r"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "t=2026-02-23T12:08:52+0530 lvl=eror msg=\"failed to reconnect session\" obj=tunnels.session err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n",
            "t=2026-02-23T12:08:52+0530 lvl=eror msg=\"session closing\" obj=tunnels.session err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n",
            "t=2026-02-23T12:08:52+0530 lvl=eror msg=\"terminating with error\" obj=app err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n",
            "t=2026-02-23T12:08:52+0530 lvl=crit msg=\"command failed\" err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n"
          ]
        },
        {
          "ename": "PyngrokNgrokError",
          "evalue": "The ngrok process errored on start: authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mPyngrokNgrokError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyngrok\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ngrok\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m public_url = \u001b[43mngrok\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m8501\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(public_url)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hiral\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pyngrok\\ngrok.py:335\u001b[39m, in \u001b[36mconnect\u001b[39m\u001b[34m(addr, proto, name, pyngrok_config, **options)\u001b[39m\n\u001b[32m    331\u001b[39m _upgrade_legacy_params(pyngrok_config, options)\n\u001b[32m    333\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOpening tunnel named: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m api_url = \u001b[43mget_ngrok_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyngrok_config\u001b[49m\u001b[43m)\u001b[49m.api_url\n\u001b[32m    337\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCreating tunnel with options: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptions\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    339\u001b[39m tunnel = NgrokTunnel(api_request(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapi_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/api/tunnels\u001b[39m\u001b[33m\"\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mPOST\u001b[39m\u001b[33m\"\u001b[39m, data=options,\n\u001b[32m    340\u001b[39m                                  timeout=pyngrok_config.request_timeout),\n\u001b[32m    341\u001b[39m                      pyngrok_config, api_url)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hiral\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pyngrok\\ngrok.py:202\u001b[39m, in \u001b[36mget_ngrok_process\u001b[39m\u001b[34m(pyngrok_config)\u001b[39m\n\u001b[32m    198\u001b[39m     pyngrok_config = conf.get_default()\n\u001b[32m    200\u001b[39m install_ngrok(pyngrok_config)\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyngrok_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hiral\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pyngrok\\process.py:271\u001b[39m, in \u001b[36mget_process\u001b[39m\u001b[34m(pyngrok_config)\u001b[39m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_process_running(pyngrok_config.ngrok_path):\n\u001b[32m    269\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _current_processes[pyngrok_config.ngrok_path]\n\u001b[32m--> \u001b[39m\u001b[32m271\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_start_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyngrok_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hiral\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\pyngrok\\process.py:447\u001b[39m, in \u001b[36m_start_process\u001b[39m\u001b[34m(pyngrok_config)\u001b[39m\n\u001b[32m    444\u001b[39m kill_process(pyngrok_config.ngrok_path)\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ngrok_process.startup_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PyngrokNgrokError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe ngrok process errored on start: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mngrok_process.startup_error\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    448\u001b[39m                             ngrok_process.logs,\n\u001b[32m    449\u001b[39m                             ngrok_process.startup_error)\n\u001b[32m    450\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    451\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PyngrokNgrokError(\u001b[33m\"\u001b[39m\u001b[33mThe ngrok process was unable to start.\u001b[39m\u001b[33m\"\u001b[39m, ngrok_process.logs)\n",
            "\u001b[31mPyngrokNgrokError\u001b[39m: The ngrok process errored on start: authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n."
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "public_url = ngrok.connect(8501)\n",
        "print(public_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miaPQZ1vmB0y"
      },
      "outputs": [],
      "source": [
        "!ngrok config add-authtoken 3A1jr34svqU716TPvq0lsL9xVNm_4YDyVovPosezctppeBFK2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yg4Uvel1nCuB"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py &>/content/logs.txt &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NSh_SRHnHUC"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "public_url = ngrok.connect(8501)\n",
        "print(public_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFmlWZTangd5"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NdM0oiDnk0Z"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py &>/content/logs.txt &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfxOR93LnrEZ"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"Public URL:\", public_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4MmGiBB-IGd"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPI3W0cl-rXG"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vBuYq59_M7l"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "\n",
        "st.set_page_config(page_title=\"Pass/Fail Predictor\", layout=\"centered\")\n",
        "\n",
        "st.title(\"ðŸŽ“ Student Pass / Fail Predictor\")\n",
        "\n",
        "st.write(\"This application predicts whether a student will PASS or FAIL based on marks and attendance.\")\n",
        "\n",
        "st.subheader(\"ðŸ“‚ Dataset Preview\")\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(\"student_pass_fail_dataset_10000.csv\")\n",
        "    st.dataframe(df.head())\n",
        "except:\n",
        "    st.warning(\"Dataset not found. Please upload the dataset.\")\n",
        "\n",
        "st.subheader(\"âœ… Deployment Status\")\n",
        "st.success(\"Streamlit app is running successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9hLLi1E_RJk"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOHVnp6T_Vhk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
